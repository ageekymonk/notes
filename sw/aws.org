* AWS CLI
** Search Images with Tags
   #+begin_src bash
     aws ec2 describe-images --filters "Name=tag:envs,Values=xxx" --profile xxx | jq -r .Images[].ImageId
   #+end_src

   #+RESULTS:
** General pattern
   - use =--query=  and =--output text= if you want to use the output of the
     command.
   - use [.fieldname] rather than .fieldname if you want newline separated
     output.
   -
* Certification
** Terminologies
   * Edge Location
     - Datacenter which does not contain aws service
     - Used to deliver content to other parts of the world (CDN)
     - Allow caching of static file
   * Elasticity
     * Proactive cycle scaling
     * Proactive Event based scaling
     * Autoscaling on demand
   * Cipher Suite
     * Authentication
     * Encryption
     * Message Authentication
     * Key Exchangen algorithms
** Virtualization
   1. HVM
      - Hardware Virtual Machine
      - Can use hardware extension for faster run
      - Can use PV drivers for network and storage
      - Recommended by AWS
   2. PV
      - Paravirtual
      - Used to be faster than HVM but not now
** Compute and Networking Services
*** EC2 Instances
    - Ondemand vs Reserved Instances vs Spot Instances vs Dedicated Instances
    - Can modify Reserved Instance in the following ways
    - Types of Dedicated Instances
      1. Dedicated Host
      2. Dedicated Instance
         - May share host with other instances from the same aws account
    - High Performance Computing
      - Jumbo Frames are supported on instance which has Enhanced Networking
      - Enhanced Networking has SR-IOV (Single Route I/O Virtualization)
      - Enhanced Networking is supported only on HVM instances not on PV Instances
    - There is a limit on number of running instances. It is 2x for number of stopped instances.
    - You can request to increase limit
    - metadata can be accessed from within aws using http://169.254.169.254/latest/metadata
    - A subnet does not span across AZ. So each AZ has to have separate Subnet
**** Reserved Instances
    - Types of Reserved Instances
      1. Standard
         - one year vs three year offering
         - Change instance size within same instance type
         - Can be sold in marketplace
      2. Scheduled
         - Reserve for only during a time
         - Scheduled Reserved instances cannot be stopped of rebooted, however they
           can be terminated and relaunched within minutes of termination
         - after purchase cannot be modified, canceled or resold
         - only supported instance types: C3, C4, M4, and R3
         - required term is 365 days (one year).
         - minimum required utilization is 1,200 hours per year
         - purchase up to three months in advance
      3. Convertible
         - the capability to change the attributes of the RI as long as the
           exchange results in the creation of Reserved Instances of equal or
           greater value
    - Attributes
      - Instance Type
      - Scope
        1. AZ RI
           1. When you purchase RI in a AZ, it provides capacity reservation
        2. Regional RI
           1. Regional Reserved Instances do not provide a capacity reservation.
           2. Availability Zone flexibility
           3. RI discount applies to instance usage regardless of size, within that instance family
      - Tenancy
      - Platform
      - Instance type modifications are supported only for Linux
      - For RedHat and SUSE the reserved instance cannot be modified
      - Cannot change instance size of window
    - Reserved Instances buying depends on
      1. Platform (for example, Linux)
      2. Instance type (for example, m1.small)
      3. Availability Zone in which to run the instance
      4. Term (time period) over which you want to reserve capacity
      5. Tenancy You can reserve capacity for your instance to run in
         single-tenant hardware or not
      6. Offering
    - Modifying Reserved Instances
      1. Switch Availability Zones within the same region
      2. Change between EC2-VPC and EC2-Classic
      3. Change the instance size within the same instance type, given the
         instance size footprint remains the same for e.g. four m1.medium
         instances (4 x 2), you can turn it into a reservation for eight
         m1.small instances (8 x 1) and vice versa. However, you cannot convert
         a reservation for a single m1.small instance (1 x 1) into a reservation
         for an m1.large instance (1 x 4).
**** High Performance Computing
     - C4 Instances for heavy workloads
     - EBS Optimized instances for 500Mbps to 4000 Mbps throughput to EBS
     - GPU Instances
     - Placement Groups for taking advantage of low latency 10Gbps network.
       Instances should support Enhanced Networking (SR-IOV)
     - Enhanced Networking is supported in certain instance type only. HVM only.
*** Instance Types
    1. General Purpose
       - T2
         - Provides *Burstable* Performance
           - 1 credit = 100% CPU for 1 minute or 50% CPU for 2 minutes etc
           - Base Performance and number of credits per hour depends on the instance type
         - Only has EBS Backed storage
         - By default,every 1GiB of disk we get 3 IOPS as baseline. So this works similar to
           CPU Credits. We can accrue
       - M3
         - SSD Storage => Fast but ephemeral. cannot detach and attach it to another instance
       - M4
         - Latest Generation
         - Only has EBS Backed Storage
         - EBS Optimized. Better Throughput
    2. Compute Optimzied
       - Lowest Cost / Performance
       - Enhanced Networking and Clusteringz
       - Types
         - C3
           - SSD Backed Storage
         - C4
           - Latest Generation
           - EBS Optimized
    3. Memory Optimized
       - Lowest Cost / GB Ram and Memory Performance
       - Types
         - R3
           - SSD Storage
           - Enhanced Networking
         - R4
         - X1
    4. GPU Optimized
       - Types
         - G3
           - High Frequency Processors
           - High Performance NVIDIA Processors
           - Onboard Hardware Video Encoders
           - Low latency Frame capture and encode
         - P2
    5. Storage Optimzied
       - Types
         - I2
           - Very Fast SSD Backed Storage with High IOPS and High Random IOPS
           - Supports TRIM
           - Supports Enhanced Networking
         - D2
           - Very High HDD Performance

*** EBS Volumes and snapshot
    - Cannot be attached to instances on different availability zones
    - Can be attached to only one instance at a time
    - EBS encryption can only available for instance type above >=m3
    - For instance type smaller than m3 use encrypted file system on EBS
    - Types of EBS Storage
      1. General Purpose SSD
         - Min 1 GiB to 16384 GiB
         - 3 IOPS per GiB
      2. Provisioned IOPS
         - Min 4 GiB to 16384 GiB
         - Min 100 IOPS to 20000 IOPS
      3. Magnetic
         - Min 1 GiB to 1024 GiB
    - Can create a volume based on a snapshot
    - To move a volume from one az to another, create a snapshot and create a volume in new az from that snapshot
    - Can degrade the performance of volume when taken snapshot. So take snapshot at non peak hours
    - Snapshot stored in s3
    -
*** Placement Groups
    - If an instance in placement group is stopped and started again it will continue to be in the placement group
    - It is suggested to have all instance within a placement group to be started at the same time
    - It is suggested to have all instance to be of same type within a placement group
    - The instance should have 10G network capacity to take advantage of placement group
    - Could receive a "Insufficient capacity error" when a new instance is added to a placement group,
      instance is stopped and started again
    - A placement group should we within a same availability zone
    - An instance which was not launched instance in a placement group cannot be moved into a placement group
    - Cannot span multiple AZ
    - Name should be unique across AWS
    - Supported only on instances that support Enhanced Networking
    - Existing instances cannot be moved to a placement group
    - Placement groups cannot be merged
    - Can span peered VPC
    - Cannot explicitly reserve instances for a placement group
    - Types: cluster and spread
    - Spread placement group has max of 7 instances per az per group
    - Autoscaling can be used but you might get insufficient capacity error
*** ELB
    - Types
      1. Classic LB
      2. Application LB
    - Classic LB
      - Region wide Load Balancer
      - Internal or External LB
      - Layer 4 and Layer 7
      - SSL Termination and Processing
      - Cookie based sticky session
      - Supported Ports
        - SMTP(25)
        - HTTP/HTTPS
        - 1024-65535
      - Does not support Elastic IP
      - Support Domain Zone Apex
      - One SSL Certificate per ELB
      - Wildcard certificate is supported
      - When using http protocol, adds *X-Forwarded-For*, *X-Forwarded-Proto*,
        *X-Forwarded-Port* header to give information about the client
      - When using TCP protocol, ELB does not add any header. But if you want,
        you can enable proxy protocol, then ELB adds human readable header to
        give information about the client
        #+BEGIN_SRC
        PROXY_STRING + single space + INET_PROTOCOL + single space + CLIENT_IP + single space + PROXY_IP + single space + CLIENT_PORT + single space + PROXY_PORT + "\r\n"
        #+END_SRC
      - Termination Rule
        - Default Rule
          #+DOWNLOADED: https://docs.aws.amazon.com/autoscaling/latest/userguide/images/termination-policy-default-flowchart-diagram.png @ 2018-01-07 06:43:32
          [[file:Certification/termination-policy-default-flowchart-diagram_2018-01-07_06-43-32.png]]
        - OldestInstance
        - NewestInstance
        - OldestLaunchConfiguration
        - ClosestToNextInstanceHour
      - Uses Perfect Forward Secrecy, which is it is not possible to decode the
        past sessions even if the long term key is compromised
      - Enable cross zone load balancing for equal distribution of traffic
        across all hosts in all az.
    - Application LB
      - Layer 7
      - Region Wide
      - supports host header (content based routing)
      - Path based Routing
      - Support for microservices and containers
      - Better performance for real time streaming
      - Deletion Protection
      - Websockets
      - HTTP/2
      - Access Logs
      - AWS WAF
      - Cross Zone Load Balancing is always enabled
    - Network Load Balancer
      - Supports Static/Elastic IP
      - Preserve Source IP Address
    - Autoscaling
      - Deployed Region wise
      - Can span across AZ
      - Components
        - Launch Configuration
        - Auto scaling Groups
        - Scaling Plans
*** VPC
**** About
     - Logically Isolated Network
     - Components
       1. Subnets
       2. Route Table
       3. Internet Gateway
       4. Elastic IP
       5. Endpoints
       6. NAT Gateway
       7. Peering Connections
       8. Network ACLs
       9. Security Groups
       10. VPN
     - Reserved IP
       - 5 IP Address in each subnet is reserved
       - First 4 IP and Last IP of every subnet
     - Subnet Types
       1. Private
       2. Public
       3. VPN
     - Subnet does not span AZ. 16 to 28 CIDR
     - Security Groups
       - Resource Level Traffic Firewall
       - Ingress and Egress
       - Stateful
       - 100 SG per VPC, 50 lines in each SG and 5 SG per instance
       - only does Destination port filtering.
       - There is no source port filtering
       - Allow rules only. There is no deny rule
       - Inbound traffic is denied by default until you allow
       - Outbound traffic is allowed until you add a single allow rule. Then it
         becomes denied for everything except the allowed one
     - NACL
       - Source and Protocol Filtering
       - Stateless
       - Default is deny all
       - Can have allow and deny rules
       - one NACL per subnet
       - Lower numbers are processed first. Stop at first match
     - Private NAT Instance
       - Supports Subnet NAT Failover
       - Scaling is done manually
       - Managed by us
       - Remember to disable Source and Destination Check
     - NAT Gateway
       - AWS Provided
       - HA is built in
       - Support Burst up to 10Gbps
       - Port Forwarding is not supported
       - Traffic Metrics is not supported
     - Endpoints
       - Allows instances in VPC to access internet services like S3 without
         going to internet from a VPC
     - VPC Peering
       - No transitive Peering
       - Will work on same or different account
       - 50 VPC Peers per VPC and can be increased to 125 by request
       - DNS is supported now
       - Security groups are not supported across peering (2014)
       - In VPC Peering two VPCs should be in separate subnet but in same region
     - VPN
       - Software VPN
       - Hardware Based VPN
         - Port Redundancy
         - There is a Virtual Private Gateway at AWS Side
         - Two parallel ipsec tunnel for redundancy
         - There can be only one virtual private gateway per vpc just like igw
         - vpc can have both virtual private gateway and igw attached at the same time
         - Create VPN Connection between Private DC and VPC
           - Create a VPN Gateway
           - Attach VPN Gateway to VPC
           - Create Customer Gateway connecting to a customer IP
             [[file:Certification/Branch_Offices_diagram_2018-01-10_21-53-19.png]]
             [[file:Certification/Multiple_VPN_Tunnels_diagram_2018-01-10_21-56-02.png]]
       - Direct Connect
         - By default does not have Port Redundancy
         - Private Connection between your datacenter to AWS Datacenter
         - Predictable Bandwidth
         - Each port is either 1Gbps or 10Gbps. Multiple ports can be bundled
           for higher speed
         - For lesser speed use APN (Amazon Partner Network)
         - Supports VLAN Trunking (802.1Q)
         - Can be partitioned into multiple VIFS (Virtual Interfaces)
           - Private VIFS
             - For accessing VPC
           - Public VIFS
             - For accessing Public services like S3
       - VPN CloudHub
         - Hardware based VPN
         - Branch offices can directly connect to AWS VPC
     - Direct Connect
       - Since Direct connect is a dedicated line, there is no internet access.
         This means you cannot access public internet.
       - You need two Direct connect for active active or active standby for ha
       - Data transferred over Direct connect is billed at lower rate
       - Reduced Latency
       - Can connect to multiple VPC using multiple VIF
       - Types of VIF
         - Public VIF
           - Allows access to public aws endpoints (s3, dynamodb). If there is no public VIF,
             you cannot access it.
         - Private VIF
           - Used to connect the DC to the VPC
           - Automatic Route discovery using BGP
           - Requires Public and Private ASN Number
           - Can communicate using only the private ip address inside vpc
       - Direct Connect Gateways
         - to connect your AWS Direct Connect connection over a private virtual
           interface to one or more VPCs in your account that are located in the
           same or different regions
           [[file:Certification/dx-gateway-diagram_2018-01-10_22-45-13.png]]
       - To connect to remote region you can create Public VIF and create as
         VPN. This will use amazon backbone for the VPN connection.
       - Cross Connect is physical connection between your network and direct connect authorized partner
       - connect from colocated DC to AWS
*** Migration to another region
    - PEM Keys are unique to a region.
    - Use automation or cloudformation template to update Autoscaling configuration
    - Use a new ELB and update dns. Have a short TTL for it to get new dns faster
    - SSL Certificates are global so you can use it across regions
** Storage and Content Delivery
*** About
    - Instance Storage Types
      1. Instance Store
         - Ephemeral
      2. EBS
         - General Purpose SSD
         - Provisioned IOPS
         - Throughput optimized HDD
         - Cold HDD
         - Magnetic
      3. EFS
         - Network Attached Storage
*** EBS
    - Does not need to be attached to an instance
    - Cannot be attached to more than one instance at a time
    - Can be transferred between AZ
    - Replicated across multiple servers in AZ
    - Can encrypt boot volumes, data volumes and snapshot
    - Annual Failure rate is 0.1 - 0.2 %
    - SLA is 99.95%
    - Volume data is replicated to multiple servers within AZ
    - I/O size is capped at 256 KiB for SSD volumes and 1,024 KiB for HDD volumes
    - Increasing IOPS than provided by using RAID. It is the function of the
      guest OS
    - RAID0 -> For increasing the IO. No redundancy
    - RAID1 -> For redundancy. No increase in IO
    - EBS Optimized Instances are available. This can be used to improve the IO
      performamce not the IOPS performance
    - In General Purpose SSD
      - you get within 10% of the baseline and burst
        performance 99.9% of time
      - Volume size is between 1 GB to 1 TB
      - Small to medium DB
      - Max IOPS 10000
      - Max Throughpout 160MB/s
      - Max IOPS/Instance 48000
      - Max Throughput/Instance 800MB/s
      - 3000 IOPS Burst for volume under 1000GB
    - Provisioned IOPS
      - In Provisioned IOPS, you get within 10% of the baseline 99.9% of time
      - 4 GB to 1 TB
      - Max IOPS/Volume 20000
      - Max Throughpout 3200MB/s
      - Max Throughput/Instance 800MB/s
    - Snapshot
      - Point in time snapshot
      - Incremental
      - Deleting a snapshot removes the blocks that are not used by any other snapshot
      - Uses S3 for storage. But it does not use a bucket
      - Used for resizing EBS Volumes
      - Sharing EBS Snapshots
      - Can be copied across regions
      - Lazy Loading. Initial loading of EBS volume from Snapshot will be low as
        it is loading from S3
      - PreWarming EBS Volumes. Use dd to read or write.
      - Can create AMI from EBS Volume
*** EFS
    - Petabyte scale filesystem for EC2 instances
    - stored redundantly across AZ
    - Many EC2 instances can be connected concurrently from multiple AZ
    - 10 EFS per account per region
    - NFS 4.0/4.1
    - can connect to onpremise via Direct connect
    - Best performance with linux kernel 4.0 or later
    - Data encryption at rest using KMS
*** S3
    - Types
     [[file:images/s3-classes.png][s3 classes]]
    - Features
      - Not a filesystem
      - Read after write consistency
      - Region level storage
      - Supports REST and SOAP Api
      - Has server side data encryption at rest
      - Synchronously stores data
      - charge based on storage and data sent out of region
      - Bucket names are unique across aws regions
      - Min size 0 bytes and max 5 TB. After 5 G, you need to use multipart
        upload. Above 100MB, Recommended to use multipart but you can use single
        upload as well.
      - Supports Transfer Acceleration
      - Object Versioning
        - stores all version including deleted and overwritten versions
        - Once Versioning is enabled it can't be disabled.
        - To disable versioning you need to emtpy the bucket and delete the bucket and recreate it
        - We can suspend versioning, so that new versions are not created
        - It is by default turned off
      - Cross Region Replication
      - Life Cycle Management
      - MFA Delete
      - Permissions
      - Time Limited access to objects
      - Requester Pay option
      - Audit logs
      - Event Notification
    - Life Cycle Policies
      - Allows an object to be sent to glacier for archival or delete after an
        interval
    - Versioning
      - unversioned, version-enabled, version-suspended
      - Objects stored in your bucket before you set the versioning state have a
        version ID of null. When you enable versioning, existing objects in your
        bucket do not change. What changes is how Amazon S3 handles the objects
        in future requests.
    - Cross Region replication
      - should have replication enabled on both source and destination
    - Security
      - Can set encryption on bucket.
      - Objects are encrypted using SSE (Server side Encryption) using SSE-S3 or
        SSE-KMS or SSE-C
      - SSE is for data encryption at rest
      - If the default encryption is enabled but there is no header in the
        request with the key details default keys will be used
      - If there is a key in the header then the encryption key is used for
        encrypting the object
      - SSE-S3
        - S3 Mananged Key
        - Encrypts each object with unique key
        - It encrypts the key with the master key that it rotates regularly
        - Uses AES-256
      - SSE-KMS
        - Uses CMK (Customer Master Key) to encrypt s3 data
      - All objects and buckets are private by default
      - Can share accounts across accounts with ACL
      - Signed URL
        - Can give access to resource url for a limited time
      - 4 levels of policies
        - IAM Policies
          - User level security
          - Granular security configuration
        - Bucket Policies
          - Bucket level security
          - Permission for anonymous user
          - Restrict IP Address / HTTP Referer
          - Limited to 20KB
        - ACL Policies
          - Legacy
          - Bucket and object level security
          - Can give permission to other accounts. cannot give to same account users.
          - Cannot grant conditional permissions neither an explicit deny
        - Query Signed Authentication (Pre signed URLs)
          - Grant temporary access to s3 resources
    - Used
      - Serve static webpages. URL is
        bucketname.s2-website-<region>.amazonaws.com
      - Serve as a origin to cloudfront CDN
      - For redirecting to another URL the bucket name has to match subdomain
    - Permissions
      - can be given access to other user account as well
      - Each bucket can have policy
*** Glacier
    - Archival Storage
    - 4 TB per archive
    - 1000 Vaults per account
    - 1 byte to 40 TB
    - Minimal storage of 90 days
    - 11 nines durability
    - Retrieval fee per GB
*** Amazon storage gateway
    - Connects local datacenter to cloud based storage like s3
    - Storage Gateway Types
      [[file:Certification/file-gateway-concepts-diagram_2018-01-13_22-07-13.png]]
      1. File Gateway
      2. Volume Gateway
         1. Cached Volume
            [[file:Certification/aws-storage-gateway-cached-diagram_2018-01-13_22-12-29.png]]
         2. Stored Volume
            [[file:Certification/aws-storage-gateway-stored-diagram_2018-01-13_22-12-46.png]]
      3. Tape Gateway
         - archive backup data in Amazon Glacier
           [[file:Certification/Gateway-VTL-Architecture2-diagram_2018-01-13_22-14-40.png]]
    - Types
      1. Gateway Cached Volumes
         - Create a volume and mount it as iSCSI Device on the onpremise server
         - The gateway will store the data written to the volume on S3
      2. Gateway Stored Volumes
         - Store data locally in storage volume
         - Gateway will take periodic snapshots as incremental backup and store it in S3
      3. Gateway Virtual Tape Library
         - exposes iSCSI interface which your back solution can back the data through
         - Virtual Tape Library is backed by S3
         - Virtual Tape Shelf is backed by glacier
*** Amazon Import/Export
    - Take onpremise data and snail mail to aws. They will store it in S3/Glacier/EBS within a day
    - They can ship back your data to you
*** Amazon snowball
*** Cloudfront
    - Global Content Delivery Network
    - Delivers content from origin location to edge location. Edge location caches files from origin location.
    - Can be used for dynamic, static, streaming, interactive content
    - s3 does not support query string but cloudfront does.
    - Distribution Types
      1. Web
      2. RTMP
    - Zone Apex
      - Route 53 alias mapping to cloudfront distribution
      - Wildcard CNAME
      - Support Subdomains
      - Supports Wildcard SSL Certificate
      - Dedicated IP Custom SSL
      - SNI Custom SSL
    - Provides Invaliation API
    - Dynamic content & Whole Site CDN
      - PUT and POST request is not cached in CDN
      - DELETE request is not cached and it does not invalidate the cache
      - For dynamic content use 0 TTL. When TTL is 0, cdn makes a HEAD request
        to check if the content is modified.
      - Device Detection based on user agent header
      - Geo Targeting
    - Reporting
      - Access Logs are sent to s3 buckets
      - Cache statistics
      - Reports
        - popular objects
        - devices, browsers, operating system
        - Top Referers
    - Security
      - Signed URLS
        - URLS with expiry date to content
      - Signed Cookies
        - More flexible.
      - Geo Restriction
        - Blacklist or whitelist countries
        - blacklisted countries see 403 error
        - Custom error pages
      - HTTP to HTTPS Redirect
      - AWS WAF
      - Generic SSL or content SSL
      - Use Origin Access Identity on cloudfront so content is only served by
        cloudfront not via s3 url
    - Performance
      - Adjust TTL with different origins using URL Patterns based on frequency
        of access and frequency of change
      - If multiple request for same object, cloudfront lets first request to
        finish so that it can use the cached object.
    - Video Streaming
      - Types
        1. On demand
           - mp4 over rtmp
           - Other media types use web cdn.
        2. Pre recorded
           - mp4 over rtmp
           - Other media types use web cdn.
        3. Live Streaming
           - web cdn not rtmp cdn
      - Signed URLs only worked for on demand and pre recorded and stored in S3.
      - Signed Cookies can be used for live streaming (Progressive Downloads)
      - Cloudfront video streaming supports only RTMP
      - Need to use web download distribution for other video types like HLS

*** Migration to another region
    - Take a snapshot of volume and migrate the snapshot to another volume
    - Use AMI Copy to another region
    - Not all AZ have ebs optimized instance types. you need to check before
** Databases
*** RDS
    - Database Engine managed by AWS
    - Supported Relational Databases: mysql, postgresql, Oracle, Sql server,
      Aurora, Mariadb
    - Aurora is homegrown mysql fork
    - Does not allow access to underlying OS
    - Min 5GB to 3 TB
    - SSD or Provisioned IOPS
    - Benefits
      1. Automatic Minor update
      2. Automatic Backups
      3. Multi-AZ
      4. Auto recovery in case of failure
      5. Do not need to manage the OS
    - Synchronous replication of data to backup
    - Backups are deleted once the database is deleted
    - We can take a snapshot of the database before it is deleted
    - Read Replicas
      - Asynchronous replication of data to read replicas
      - If security is enabled then the read replicas has to be in the same region
      - Can be created from other read replicas
      - Monitor replication lag using cloudwatch
      - Can promote a read replica to a primary instance
      - mysql: relicate to other regions
      - mysql: replicate to rds from our mysql instance
      - can be used in
    - Oracle and Mysql
      - Supports included licenses
      - Supports BYOL
    - Backups
      - Automated
        - Volume snapshot of entire DB Instance not just db
        - one day backup retained by default
        - Can be configured upto 35 days
        - On deletion all automated snapshots are deleted
      - Manual
        - on deletion the manual snapshots are retained
    - Restore
      - Point in time during the retention period until last 5 mins
    - Multi AZ
      - Standby Instance available
      - Snapshots are taken on the standby instance
      - synchronous replication
      - It is different from Read Replica
    - Reserved Instance
      - If modifed the following params then it loses reservation
        1. DB Engine
        2. DB Instance Class
        3. Deployment Type
        4. License Model
        5. Region
    - Replication
      - From RDS to on premise
      - From on premise to RDS
    - Oracle DB
      - Oracle RAC is not supported by RDS because AWS does not support multicast.
      - We can run Oracle RAC by using a Tunnel between all the nodes in the
        cluster
      - Can use RMAN to export data from on premise to S3
      - RMAN is not supported in RDS so need to use RDS Snapshot
      - Oracle DB import is done by Oracle Data pump
    - MSSQL
      - Read Replicas are not supported
      - multi region disaster recovery and backups require import/export tools
        provided by sql server
      - Can copy rds snapshot from one region to another region
    - Security
      - Encryption of data at rest
      - If encrypted the snapshot, logs, backups, read replicas are encrypted
      - Encryption can only be enabled at creation time
      - Cross region replicas and copying snapshot to another region will not
        work as the keys are specific to region
      - Transparent Data Encryption
        - Automatically encrypts the data before writing to the storage device
        - Native feature of Oracle and SQL Server
        - In Oracle the key needs to be stored outside of KMS. It can integrate
          with HSM for this
        - In SQL Server, the key is managed by RDS after enabling TDE
      - SSL Endpoints can be used

*** Elasticache
    - Inmemory cache engine
    - Supported: memcached, redis
    - Master Slave Replication and Multi AZ
    - When to use Memcached instead of Redis
      1. Multi threaded
      2. Horizontal Scaling
      3. When using DB as a source like mariaDB/mysql
      4. does not have its own persistence
      5. write through and lazy loading supported
      6. every node should be same instance type
    - When not to use Memcached but use redis
      1. Multi AZ
      2. Backup and Restore
      3. Pub/Sub Functionality
      4. Sorting and Ranking
      5. Advanced data types
      6. Persistence
      7. acts replacement for db
      8. persistence is disabled by default
      9. Scale by adding read replicas
    - Caching Strategies
      - Lazy Loading
        - more common in memcached
        - if there is a request first checked in elasticache if there is a miss,
          it is requested from db and updated the elasticache
        - It is good strategy for frequently accessed data
      - Write through
        - updated when written to the db
        - good strategy when there is not many writes
        - Lot of data stored in memory, many could be infrequently accessed
      - Adding TTL
        - this can be used in both lazy loading and write through
*** DynamoDB
    - Homegrown Nosql
    - Fully Managed, Highly Available, Highly Scalable
    - Automatic Synchronous replication to 3 AZ
    - Backed by SSD
    - Provides High Throughput and Low Latency
    - Can add Elasticache infront of it
    - Non ideal for
      1. Prewritten Relational db apps
      2. Has lots of joins and complex transactions
      3. BLOB data
      4. Large data with low IO rate
    - Integration
      - Amazon EMR
      - Amazon Redshift
      - Amazon Data Pipeline
      - Amazon S3
    - Stores structured data in tables and indexed by a primary key
    - primary key can be single attribute hash key (now it is called as
      partition primary key) or composite hash-range key (partition primary
      key + Sort key)
    - Supports secondary indexes
    - Supports get for all item level changes occured in some time frame. It is
      called stream
    - Cross Region Replication
    - Triggers to integrate with lambda
    - Schema less
    - Operations for searching
      - Query
        searches the index
      - Scan
        grep every item
    - Global Secondary Index
      - using different secondary partition key and sort key
    - Local Secondary Index
      - using same partition key as primary key but different sort key
    - Multiregion replication
      - for RPO and RTO we can use data pipeline to transfer data to secondary region
    - Dynamodb streams
      - powered by kinesis
      - from the dynamodb table log is written to kinesis
*** Redshift
    - Petabyte scale data warehousing for storing large amounts of data for BI applications
    - Analyze all your data using existing BI tools
    - Redshift nodes are all within single availability zone
    - Redshift nodes are continuously backed to s3. In case of node failure, the
      data is restored from s3
    - HDD and SSD
    - Does not support spot instance
    - Shutting down a cluster will create a snapshot and delete the cluster
    - delete a cluster will not create a snapshot
    - There is not shutdown for cost saving purpose. Cluster is running or deleted.
    - Architecture
      - Has Leader Node which is just a SQL Endpoint
      - Leader node stores
        1. Metadata
        2. Optimizes Query plan
        3. coordinates query execution
        4. Distributes the query in parallel to all cluster nodes
        5. Results from all the cluster nodes are organized and sent to client
      - Compute Nodes
        1. Local Columnar storage
        2. Parallel / distributed execution of queries, loads, backups, restores
           and resizes
      - Continuous and incremental backups
        - can take snapshot and create a new cluster from that. The snapshot is
          stored in s3
        - Automatic and manual snapshot are available.
        - The snapshots can be copied across regions
        - Supports automatic and manual copy of snapshots across regions
      - Security
        - Load encrypted data from S3
        - SSL encryption on flight
        - encrypt data at rest
** Route 53
*** About
    - World wide distributed DNS
    - 100% SLA Uptime
    - Public Hosted Zone
    - Private Hosted Zone for Amazon VPC
    - You cannot extend Route53 to manage on premises instances
    - Cannot automatically register EC2 instance with private hosted zone
    - Routing
      - Single
        - Associate an A Record with one or more IP addresses
        - For multiple IP addresses, it will roundrobin
        - Does not do health check
      - Weighted
        - Can specify Weights for each ip addresses
      - Latency
        - AWS will maintain the database of latency for all the servers from
          different parts of the world
        - Sends to lowest latency server
      - Failover
        - Switches to secondary if primary fails health check
      - Geolocation
        - Route to server based on location
*** DNS Record Types
    | Type  | Uses                      |
    | A     | Address Record            |
    | CNAME | Canonical Name Record     |
    | MX    | Mail Exchange             |
    | AAAA  | IPV6 Record               |
    | TXT   | Text Record               |
    | PTR   | Pointer Record            |
    | SRV   | Service Locator           |
    | SPF   | Sender Policy Framework   |
    | SOA   | Start of Authority Record |
    | NS    | Nameserver Record         |

    - PTR is opposite of A Record
    - SPF is to avoid spoofing. My email server will send from only these IP
      address listed in SPF
    - NS is the list of nameserver for your domain
    - SOA is the first nameserver in the NS list.

** Analytics
*** Elastic Mapreduce (EMR)
    - Hadoop Clustering tool
    - Easily integrate with Redshift, DyanmoDB, data pipeline
    - Full access to underlying OS
    - Supports Hadoop, Spark, HBase, Presto, Flink
    - 128 MB Chunks
    - Hadoop Components
      - HDFS
      - Map reduce
      - Hadoop Data services
        - Hive
        - Pig
    - EMR Cluster Components
      1. Master Node
         - manages data distribution to core nodes
         - manages task nodes
      2. Core Node
         - runs task
         - store data in HDFS
      3. Task Node
         - runs tasks
      4. EMRFS
         - use EMRFS instead of HDFS. store data in s3
*** Kinesis
    - Development service
    - Can capture and store real time streams of data
    - By default it is stored for 24 hours. It can be increased to 7 days
    - Benefits
      - Real time processing
      - Parallel Processing
      - Durable
      - Scale
    - Streams Terminology
      - Producers
        - can use Kinesis Streams API
        - Kinesis Producer Library (KPL)
        - Kinesis Agents
      - Data Records
        - Each data record has unique sequence number
        - Max size of data blob is 1 MB after base64 decoding
      - Shards
        - Uniquely Identified Streams of Records in a stream
        - A stream can have one or more shards
        - Support 5 transactions per second for reads
        - Max total read rate is 2 MB/s and 1 MB/s for write
        - 1000 records per second for writes
        - As data rate increases you need to increase the number of shards
        - Partition key is for shard to partition a stream
      - Consumers
        - Also called as Kinesis stream application
*** Data Pipeline
    - automating transfer or transformation of data
    - Move data from and to other services
    - Components
      - Task Runners
        - an application polling the pipeline for task and performs the task
        - can be a prebuilt template that launches ec2 instance, or use existing
          ec2 instance or on premise server
      - Data nodes
        - The location and type of data the pipeline uses for input and output
        - example: dynamodb, mysql, redshift, s3
      - Activities
        - This defines what is to be done
      - Preconditions
        - condition that should be satisfied to execute a pipeline
      - Resources
        - computational resources like EMR, EC2
** App Services
*** Simple Workflow (SWF)
    - Useful for coordination of distributed tasks
    - Track Workflow Executions
    - Service can be used with onpremise servers
    - Guarantees order of tasks that are executed
    - No duplicate tasks
    - Can last for an year
    - Each workflow runs in an AWS resource called a domain,
    -
    - Components
      1. Tasks
         - Activity Task
           Tells the worker to perform a function
         - Decider Task
           Tells the decider the state of workflow execution
      2. Worker
         - Can be EC2 instance or a person
         - Receives and performas tasks
*** Simple Queue Service (SQS)
    - Short Polling(0 seconds) and Long Polling (1 - 20 seconds)
    - Each message is max of 256KB of data. Minimum should be 1 byte.
    - Max message retention time is 14 days. Default is 4 days
    - Delivery Delay 0 seconds to 15 minutes. Message is not visible until then
    - Types of Queus
      1. Standard
         - Guarantees deliver of messages atleast once
         - Does not guarantee on order. Best Effort
         - 300 Message per second without batching. 3000 with batching
         - Max 120,000 inflight message per queue
      2. FIFO
         - No duplicates
         - FIFO
         - Max 20000 inflight message per queue
    - Job Observer Pattern
      - cloudwatch alarm to trigger when the sqs queue reaches a threshold
      -
*** Simple Notification Service (SNS)
    - sending messages to endpoints
    - Components
      1. Topic
         - Group of subscription that you send a message to
      2. Subscription
         - An endpoint
         - Endpoints are http, https, email, sqs, Lambda, sms, Mobile app notification
      3. Publisher
         - Entity that triggers the send
         - Human, S3 Event, Coudwatch Alarm
*** API Gateway
    - Fully managed API for your application
    - Supports different envs like dev, stage, prd
    - API Versioning
    - Throttling
    - Swagger is supported
    - Can send to external other api
    - Cache response with TTL
    - Uses cloudfront for entry. It helps in DDoS
*** Elastic Transcoder
    - Convert media files on s3
    - Convert different formats (HTTP Live Streaming HLS), quality levels, resolutions, apply captions,
      create mp3 from video, watermark video files
    - can use S3 RRS to stored the results of transcoding as we have the source
      files and we can get the output any time from source
    - Components
      - Jobs
        - can create upto 30 different video types
        - we configure video settings, presets for videos, encoding
      - Pipelines
        - Pipelines are where jobs are submitted
        - we configure source and destination s3 bucket
      - presets
        - these are configuration for videos
** Deployment Services
*** Elastic Bean Stalk
    - Deploying and Scaling Web Application
    - Fault tolerant within a region but not between region
    - By default the application is publicly accessible
    - For Simple Applications
    - Full control of resources
    - Integrates with VPC, IAM
    - Multiple Environments supported
    - Deploy using war file or git repository
    - Cloudwatch Monitoring, Application server settings, Run other application
      components, Access log files without logging into application servers
*** EC2 Systems Manager
**** About
     - Hybrid
     - Cross Platform
     - Scalable
     - Run command
       - Can create custom command by creating a json document
     - State Manager
       - Define and maintain consistent configuration of OS and applications
     - Automation Service
       - Automate common tasks using simplified workflow
     - Parameter Store
       - Centralized management of passwords and connections strings
     - Maintainence Window
     - Inventory Service
     - Patch Manager
*** AWS Opsworks
    - Supports Chef and Puppet
    - Terminology
      - Stacks and Layers
        - Stacks are containers of resources that you want to manage
        - Stacks contains one or more layers. Example Web application layer,
          database layer
    - Rolling Deployment
    - Blue Green Deployment
    - Supports both on premise and aws
*** Cloudformation
    - Templates and Stacks
      - Template is the blueprint
      - Stacks are resources deployed based on template
      - Changesets are summary of your proposed changes when you update stack
    - Template
       #+BEGIN_SRC
      ---
      AWSTemplateFormatVersion: "2010-09-09"

      Description:
        String

      Metadata:
        template metadata

      Parameters:
        set of parameters

      Mappings:
        set of mappings

      Conditions:
        set of conditions

      Transform:
        set of transforms

      Resources:
        set of resources

      Outputs:
        set of outputs
           #+END_SRC
      - Resources is the only mandatory section rest are all optional.
      - Description should be between 0-1024 bytes. Cannot use parameters or functions.
      - Metadata section to include arbitrary JSON or YAML objects that provide
        details about the template
      - During a stack update, you cannot update the Metadata section by itself. You can update it only when you include changes that add, modify, or delete resources.
      - Max number of parameter in template should be 60
      - Parameter is referenced in Resources using "Ref" intrinsic function
      - Mappings section matches a key to a corresponding set of named values.
        Use Fn::FindInMap to retrieve value in map
      - Conditions section includes statements that define when a resource is created or when a property is defined
      - Transforms are macros. Supported Transforms AWS::Serverless and AWS::Include
      - Output section defines output values that can be used in other stacks.
        This is done by Export.
      - Output value limit is 60.
      - Puppet and Chef Integration
      - VPC Peering in same VPC account is supported
      - But default automatic rollback is enabled
      - AWS CloudFormation StackSets extends the functionality of stacks by
        enabling you to create, update, or delete stacks across multiple accounts
        and regions with a single operation.
      - Nested Templates are supported
      - CloudFormation can backup or retain resources or snapshot when the cloudformation
        template is deleted
      - You can use intrinsic functions only in specific parts of a template.
        Currently, you can use intrinsic functions in resource properties,
        outputs, metadata attributes, and update policy attributes. You can also
        use intrinsic functions to conditionally create stack resources.

** Management Services
*** Identity Access Management (IAM)
    - Central control of AWS Resources
    - Consolidated Billing for users
    - Ensure user access from only specific network
    - Federate with SAML Providers
    - Provides Roles
    - Roles
      - User/Resources to assume certain permissions
    - Security Token Service
    - Best practice for new account
      - Do not login with root access
      - Create admin User
      - Use groups to create access for users
      - Use MFA
      - Set Password policy
    - An EC2 instance can be given role when it is created and can have only one role
*** Directory Services
    - AD Connector
      - Hosted Proxy service
      - Nothing is stored
      - Increased latency
    - Simple AD
      - Fully hosted AD
      - Setup Master Controller and sync to onpremise
** Development Services
*** Kinesis
    - Realtime data processing service which continuously captures and store data
      and realtime streaming of the data for dashboards
    - One shard = 1 MB/s. Scale number of shards as required
    - Advantage
      1. Realtime processing
      2. Parallel Processing
      3. Durable
         - replicates data across three data center within a region
         - Preserves data for 24 hours upto 7 days
      4. Scalability
         - scales from few MB to several TB per hour
    - Workflow
      1. Create a stream
      2. Build producers to send data to the stream
      3. Consumers consume concurrently
** Security
*** Root Account
    1. Delete your root keys
    2. Activate MFA on root account
    3. Create Individual IAM Users
    4. Use groups to assign permissions
    5. Apply an IAM Password policy
    6. Create a terraform user who has programmatic access
    7. Add terraform user to admin group
    8. Create a credential for terraform
*** IAM
**** About
    - Identity and Access Management
    - Users, Groups, Roles and Policies
    - MFA
    - API Access
    - Cannot Nest Groups
    - For EC2 Instance a role can be assigned only when it is launched
    - AWS Security Token Service
      - Federated Temporary access to AWS Resources
      - Enterprise Identity Federation
        - SAML 2.0
          - LDAP, AD FS
      - Web Identity Federation
        - Google
        - Twitter
        - Amazon
        - Facebook
    - Use Access Advisor to find out overtly permissive policy
**** Best Practices
     1. Always create individual users
     2. Configure a strong password policy
     3. Rotate Security Credentials Regularly
     4. Enable MFA for privileged users
     5. Manage Permissions with group
     6. Grant Least Privilege
     7. Use IAM Roles to share access
     8. Use IAM Roles for EC2 instances
     9. Enable AWS CloudTrail to get logs of API Calls
     10. Remove use of Root
*** Web Application Firewall (WAF)
*** Security Token Service (STS)
    - Can be used to give temporary access credentials
    - endpoint is [[https://sts.amazonaws.com]]
    - Max time for the key is 12 hours
    - [[https://169.254.169.254/latest/meta-data/iam/security-credentials/role-name]]
    - Identity Federation with custom identity broker
      - calls AssumeRole or GetFederationToken
      - GetFederationToken is the key is valid for longer duration and does not
        support MFA
      - Assume role the key is valid for short durationa and support MFA
      #+attr_html: :width 600px
      [[file:Certification/enterprise-authentication-with-identity-broker-application.diagram_2018-01-08_20-02-49.png]]
    - Identity Federation with SAMLG
      #+attr_html: :width 600px
      [[file:Certification/saml-based-sso-to-console.diagram_2018-01-08_19-59-00.png]]
    - Identity Federation with Web Identity Providers
      - Can replace AssumeRoleWithWebIdentity call by using cognito
        #+attr_html: :width 600px
        [[file:Certification/aws-may-webinar-series-getting-started-with-aws-identity-and-access-management-25-638_2018-01-08_20-00-39.jpeg]]
*** security group
    - Resource Level
    - Ingress and Egress
    - Stateful
      - Return Traffic allowed
    - Only destination port filtering. Does not have source port filtering
    - 5 security group per resource
    - 500 SG per VPC
    - 50 Rules per SG
    - All rules are denied unless specifically applied
    - in EC2-Classic you cannot change sg once launched
    - In VPC-EC2 you can change sg once launched
    - Responses to Inbound traffic are allowed regardless of outbound rules(stateful)
    - Responses to Outbound traffic are allowed regardless of inbound rules
*** KMS
    - Per region
    - create and control encryption keys
    - Uses Hardware HSM to protect keys
    - Supports only symmetric encryption. Same secret key for both encryption
      and decryption
    - Customer Master Key (CMK)
      - Logical key that represents top of the customer's key hierarchy
      - It has an alias
      - If another key is not specified CMK is used for encryption
      - Supports key rotation
      - It can only encrypt 4096 of data directly
    - Data Key
      - Used to encrypt large objects directly
    - Envelope Encryption
      - Uses this to protect data
      - practice of encrypting data using data key and encrypting the data key
        using Key Encryption Key (KEK)
    - Quorum based access. No amazon employee can get access to CMK
    - Access control using IAM
    - Low latency and high throughput
    - KMS is made of domains and domain is a regionally defined set of KMS servers
    - To delete there is a wait period from 7 days to 30 days. default is 30 days
    -
*** DDOS Attack
    - Types of attack
      1. udp flood
      2. http flood
      3. syn flood
    -
** Monitoring
*** Status Checks
    1. System
       - Involves AWS to fix the issue
       - Examples:
         - Loss of Network Connectivity
         - Loss of System Power
         - Software Issues on Physical Host
         - Hardware Issues on Physical Host
    2. Instance
       - Examples
         - Failed System Status Checks
         - Incorrect networking or startup configuration
         - Exhausted Memory
         - Corrupted filesystem
         - Incompatible Kernel
*** Cloudwatch
    - Monitoring service for aws resources
    - Collects and Tracks metrics
    - Collects and monitors log files
    - Set Alarms
    - Can react to changes in AWS Resources
    - Metrics
      - Some metrics are not shown by default as they can't find out from VM level.
        For those metrics we need to run scripts inside the OS to measure and send
        to AWS.
    - Detailed Monitoring - 1 min interval but charged
    - Basic Monitoring - 5 min interval but free
    - By default the cloudwatch logs are stored indefinitely
    - Alarm history is stored is 14 days
    - Can store logs in CloudWatch Logs or external system like splunk or s3
    - EC2 can store logs in cloudwatch
      1. Create a role where ec2 instance is allowed to write logs to cloudwatch
      2. Install awslogs package
      3. edit /etc/awslogs/awscli.conf and /etc/awslogs/awslogs.conf
      4. service awslogs start
      5.
*** CloudTrail
    - Log all actions taken on aws
    - Since every action is api driven. Cloud Trail monitors it
    - Recorded information includes
      - Identity of API Caller
      - Time of call
      - Source address
      - Request Params
      - Response
    - Not enabled by default.
    - Can be enabled per region
    - Used for
      1. Security Analysis
      2. Compliance Aid
      3. Track and Monitor
      4. Troubleshoot
*** Trusted Advisor
    - Service that help you reduce cost by specifying how to reduce cost,
      increase performance and security
    - Automated AWS Audits
*** Flog Logs
    - Can be enabled per subnet, interface or vpc
      - Information about IP Traffic to and from network interfaces
      - Can be enabled at VPC level, subnet level or interface level
      - Each event of flow log contains
        1. flow log version
        2. aws account id
        3. network interface id
        4. src ip
        5. network interface ip
        6. destination ip
        7. src port
        8. destination port
        9. number of packets
        10. number of bytes
        11. action accepted or rejected
** Disaster Recovery
   - RTO
     - Recovery Time Objective
     - Time taken to restore regular operation after disaster
   - RPO
     - Recovery Point Objective
     - Amount of data loss
   - Pilot Light
     - Only Core part of Application running on AWS
   - Warm Standby
     - Warm standby is a method of redundancy in which the secondary system
       runs in the background of the primary system. Data is mirrored to the
       secondary server at regular intervals,
       which means that there are times when both servers do not contain the exact same data.
   - Hot Standby

** Billing
   - Bulk and Volume discounts span across accounts in consolidated billing
   - Ability to view bills per account
   - Use roles for IAM account across multiple linked AWS Accounts
   - All Linked accounts on a consolidated bill can receive the hourly cost benefit of EC2 Reserved Instances purchased by any other account
   - Best practices
     - Never run any resource in the consolidated payee account
     -
** TO Research
   - Moving Oracle DB from onpremise to AWS
   - IDS/IDP
     -
